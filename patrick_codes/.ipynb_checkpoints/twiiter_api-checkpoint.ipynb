{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook would be used to Fetch Twitter Data via Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API  \n",
    "from tweepy import Cursor\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from collections import Counter\n",
    "import os, sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load dotenv to expose api keys to the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY API_SECRET_KEY ACCESS_TOKEN ACCESS_TOKEN_SECRET\n"
     ]
    }
   ],
   "source": [
    "API_KEY=\"API_KEY\"\n",
    "API_SECRET_KEY=\"API_SECRET_KEY\"\n",
    "ACCESS_TOKEN=\"ACCESS_TOKEN\"\n",
    "ACCESS_TOKEN_SECRET=\"ACCESS_TOKEN_SECRET\"\n",
    "print(API_KEY, API_SECRET_KEY, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.environ.get(API_KEY)\n",
    "API_SECRET_KEY = os.getenv(API_SECRET_KEY)\n",
    "ACCESS_TOKEN = os.getenv(ACCESS_TOKEN)\n",
    "ACCESS_TOKEN_SECRET=os.getenv(ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(API_KEY, API_SECRET_KEY)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "auth_api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Testing Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @IQAir: Cold and flu season are almost here, and air pollution could prolong your illness.  Learn the facts about air quality and protec…\n",
      "Keep a constant eye on your home’s air quality in this Pandemic with this Gadget.\n",
      "#topfiveme #airqualitymeters #bestairqualitymeters #airquality #easybreathing #bettersleep #cleanair #coronavirus #COVID-19 #stayhomestaysafe\n",
      "Source: https://t.co/wVqBcBDpkB https://t.co/TZ7CQQTpIM\n"
     ]
    }
   ],
   "source": [
    "search_words = \"airquality\"\n",
    "date_since=\"2020-03-03\"  \n",
    "# Collect tweets\n",
    "tweets = tweepy.Cursor(api.search,\n",
    "              q=search_words, tweet_mode='extended',\n",
    "              lang=\"en\", \n",
    "              since=date_since\n",
    "                      ).items(2)\n",
    "# Iterate and print tweets\n",
    "for tweet in tweets:\n",
    "    print(tweet.full_text)\n",
    "   # print(tweet._json['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @AguGeohealth: Are you a #BlackGeoscientist (anywhere in the world!) who is interested in how our environment and Earth impacts human he…\n",
      "RT @cleanaironea: 1/n\n",
      "While this is preliminary, we have tried to firstly test our open source data mining tools plus compare current trend…\n"
     ]
    }
   ],
   "source": [
    "tweets = Cursor(api.user_timeline, id='WestAfricaAQ',\n",
    "               tweet_mode='extended',\n",
    "              lang=\"en\", count=10).items(2)\n",
    "for tweet in tweets:\n",
    "    print(tweet.full_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TWITTER API ALL SET UP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags= ['#airquality ','#cleanair','#airpollution' ,'#pollution',\n",
    "           '#hvac', '#airpurifier', '#indoorairquality','#health',\n",
    "           '#covid', '#air', '#climatechange',' #indoorair',\n",
    "           '#environment','#airconditioning', '#coronavirus', '#heating',\n",
    "           '#mold', '#freshair', '#safety', '#ac', '#airfilter', '#allergies',\n",
    "           '#hvacservice', '#ventilation','#wellness','#delhipollution',\n",
    "           '#airconditioner','#airqualityindex','#bhfyp',\n",
    "           'particulate matter', 'fine particulate matter','#pm2_5',\n",
    "           '#emissions', '#natureishealing','#nature','#pollutionfree',\n",
    "           '#wearethevirus']\n",
    "\n",
    "accounts = ['@GhanaAQ','@asap_eastafrica', '@WestAfricaAQ']\n",
    "\n",
    "\n",
    "geocodes = {'lagos':(\"6.48937,3.37709\"),'cape_town':(\"-33.99268,18.46654\"),\n",
    "            'joburg' : (\"-26.22081,28.03239\"),\n",
    "            'accra' : (\"5.58445,-0.20514\"),\n",
    "            'nairobi' : (\"-1.27467,36.81178\"),\n",
    "            'mombasa' : (\"-4.04549,39.66644\"),\n",
    "            'kigali' : (\"-1.95360,30.09186\"),\n",
    "            'kampala' : (\"0.32400,32.58662\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'65'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = geocodes['lagos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.48937,3.37709,7km'"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+','+str(7)+'km'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.48937,3.37709'"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting GetOldTweets3\n",
      "  Downloading GetOldTweets3-0.0.11-py3-none-any.whl (13 kB)\n",
      "Requirement already satisfied: lxml>=3.5.0 in /home/patrick/.local/lib/python3.6/site-packages (from GetOldTweets3) (4.5.0)\n",
      "Requirement already satisfied: pyquery>=1.2.10 in /home/patrick/.local/lib/python3.6/site-packages (from GetOldTweets3) (1.4.1)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /home/patrick/.local/lib/python3.6/site-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n",
      "Installing collected packages: GetOldTweets3\n",
      "Successfully installed GetOldTweets3-0.0.11\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install GetOldTweets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `got.manager.TweetCriteria()` not found.\n"
     ]
    }
   ],
   "source": [
    "got.manager.TweetCriteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweetCriteria = got.manager.TweetCriteria().setQuerySearch('europe refugees')\\\n",
    "#                                            .setSince(\"2015-05-01\")\\\n",
    "#                                            .setUntil(\"2015-09-30\")\\\n",
    "#                                            .setMaxTweets(1)\n",
    "# tweet = got.manager.TweetManager.getTweets(tweetCriteria)[0]\n",
    "# print(tweet.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetCursor():\n",
    "    \n",
    "    import tweepy\n",
    "    from tweepy import OAuthHandler\n",
    "    from tweepy import API  \n",
    "    from tweepy import Cursor\n",
    "    from dotenv import load_dotenv\n",
    "    import os, sys\n",
    "\n",
    "    \n",
    "    def __init__(self,env_file=None):\n",
    "        if env_file is None:\n",
    "            self.env = load_dotenv('../.env')\n",
    "        else:\n",
    "            self.env = load_dotenv(env_file)\n",
    "            \n",
    "    \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return \"Twitter API Auth Object\"\n",
    "            \n",
    "    \n",
    "    def get_auth(self):\n",
    "        \n",
    "        API_KEY=\"API_KEY\"\n",
    "        API_SECRET_KEY=\"API_SECRET_KEY\"\n",
    "        ACCESS_TOKEN=\"ACCESS_TOKEN\"\n",
    "        ACCESS_TOKEN_SECRET=\"ACCESS_TOKEN_SECRET\"\n",
    "        \n",
    "        self.__API_KEY = os.environ.get(API_KEY)\n",
    "        self.__API_SECRET_KEY = os.getenv(API_SECRET_KEY)\n",
    "        self.__ACCESS_TOKEN = os.getenv(ACCESS_TOKEN)\n",
    "        self.__ACCESS_TOKEN_SECRET=os.getenv(ACCESS_TOKEN_SECRET)\n",
    "        \n",
    "        try:\n",
    "            self.__auth = OAuthHandler(API_KEY, API_SECRET_KEY)\n",
    "            self.__auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "            self.api = API(auth, wait_on_rate_limit=True)\n",
    "            self.auth_api = API(auth, retry_count=5,retry_delay=5,\n",
    "                               timeout=60, \n",
    "                                wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "            \n",
    "        except tweepy.TweepError as e:\n",
    "            print(e.reason())\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetTweets(GetCursor):\n",
    "    \n",
    "    # import dependencies\n",
    "    \n",
    "    import tweepy\n",
    "    from tweepy import Cursor\n",
    "    from datetime import datetime, date, time, timedelta\n",
    "\n",
    "    \n",
    "    def __init__(self,env_file=None):\n",
    "        super().__init__(env_file)\n",
    "        self.get_auth()\n",
    "        print('Authentication successful')\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Get tweets from Hashtags -> # & Users -> @\"\n",
    "    \n",
    "    \"\"\"\n",
    "    helper functions  \n",
    "    \n",
    "    1. limit_handled - handle wait_limit error\n",
    "    2. check_is_bot - check if handle is a bot\n",
    "    3. save_result - save data to a file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def limit_handled(cursor):\n",
    "        while True:\n",
    "            try:\n",
    "                yield cursor.next()\n",
    "            except tweepy.RateLimitError:\n",
    "                time.sleep(15 * 60) #default 15mins\n",
    "                \n",
    "    \n",
    "    def check_is_bot(self, handle)-> bool:\n",
    "        \n",
    "        self.is_bot = False\n",
    "        account_age_days = 0\n",
    "        \n",
    "        item = self.auth_api.get_user(handle)\n",
    "        account_created_date = item.created_at\n",
    "        delta = datetime.utcnow() - account_created_date\n",
    "        account_age_days = delta.days\n",
    "        if account_age_days < 180: #(6 months)\n",
    "            is_bot=True\n",
    "            \n",
    "        return self.is_bot\n",
    "        \n",
    "    def save_result(self, data:pd.DataFrame, path:str='../saved_data/',\n",
    "                    fname='new_file'):\n",
    "        \n",
    "        data.to_csv(path+name, index=False)\n",
    "            \n",
    "    \n",
    "    \n",
    "    def get_handle_tweets(self, handles:list=[], items_count=20):\n",
    "        self.handles = handles\n",
    "        \n",
    "        if len(self.handles) > 0: \n",
    "            for handle in self.handles:\n",
    "                print(f\"collecting tweets of -> {handle}\")\n",
    "                users_tweets = {}\n",
    "                # this helps avoid Tweepy errors like suspended users or user not found errors\n",
    "                try: \n",
    "                    item = self.auth_api.get_user(handle)\n",
    "                except tweepy.TweepError as e:\n",
    "                    print(\"found errors!!!\")\n",
    "                    continue\n",
    "                    \n",
    "                #check if handle is a potential bot    \n",
    "                if self.check_is_bot(handle):\n",
    "                    print('bot alert!!!, skipping the bad guy :(')\n",
    "                    continue\n",
    "                else:\n",
    "                    current_handle_tweets = Cursor(api.user_timeline, id=handle,\n",
    "                                                        tweet_mode='extended',\n",
    "                                                        lang=\"en\").items(items_count)\n",
    "                    \n",
    "                for tweet in current_handle_tweets:\n",
    "                    users_tweets[handle] = ({'tweet_text':tweet.full_text.encode('utf-8'),\n",
    "                                             'tweet_date':tweet._json['created_at']})\n",
    "        \n",
    "        self.handles_data = pd.DataFrame(users_tweets).T\n",
    "            \n",
    "        return self.handles_data\n",
    "               \n",
    "    \n",
    "    def get_tag_tweets(self, tags:list=[], geocode:str=None,\n",
    "                       radius:int=None,\n",
    "                       until_date:str=\"2020-03-30\", no_of_items=10):\n",
    "        \n",
    "        \"\"\"\n",
    "        until_date should be formatted as  YYYY-MM-DD\n",
    "        \n",
    "        geocode should be used \n",
    "        \"\"\"\n",
    "        #if geocode is not None\n",
    "        self.tags = tags \n",
    "        tags_tweets = {}\n",
    "        for tag in self.tags:\n",
    "            print(f\"collecting tweets of -> {tag}\")\n",
    "            if radius is not None and geocode is not None:\n",
    "                geocode = geocode+','+str(radius)+'km'\n",
    "            current_tag_tweets = tweepy.Cursor(api.search,\n",
    "                                               q=tag, tweet_mode='extended',\n",
    "                                               lang=\"en\", \n",
    "                                               since=until_date,\n",
    "                                               geocode=geocode,\n",
    "                                              ).items(no_of_items)\n",
    "            \n",
    "            \n",
    "            for tweet in current_tag_tweets:\n",
    "                tags_tweets[tag] = ({'tweet_text':tweet.full_text.encode('utf-8'),\n",
    "                                     'tweet_date':tweet._json['created_at']})\n",
    "            \n",
    "        self.tags_data = pd.DataFrame(tags_tweets).T\n",
    "        \n",
    "        return self.tags_data\n",
    "\n",
    "    \n",
    "def main():\n",
    "    return \"wip\"\n",
    "    \n",
    "if __name__== main():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful\n"
     ]
    }
   ],
   "source": [
    "get_tweet= GetTweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_tags = ['#airquality']#,'#cleanair','#airpollution' ,'#pollution',\n",
    "           #'#hvac', '#airpurifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_accounts = ['@GhanaAQ']#,'@asap_eastafrica', '@WestAfricaAQ']created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> test for tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting tweets of -> #airquality\n"
     ]
    }
   ],
   "source": [
    "trial_tags_result  = get_tweet.get_tag_tweets(trial_tags) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#airquality</th>\n",
       "      <td>Wed Sep 30 23:56:37 +0000 2020</td>\n",
       "      <td>b'RT @neosensory: We have a WINNER: Chris Bart...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 tweet_date  \\\n",
       "#airquality  Wed Sep 30 23:56:37 +0000 2020   \n",
       "\n",
       "                                                    tweet_text  \n",
       "#airquality  b'RT @neosensory: We have a WINNER: Chris Bart...  "
      ]
     },
     "execution_count": 246,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_tags_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> test for accounts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting tweets of -> @GhanaAQ\n"
     ]
    }
   ],
   "source": [
    "trial_account_results = get_tweet.get_handle_tweets(trial_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>@GhanaAQ</th>\n",
       "      <td>Tue Jan 14 19:47:41 +0000 2020</td>\n",
       "      <td>RT @subu_caps: Nice video of @albertpresto tal...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              tweet_date  \\\n",
       "@GhanaAQ  Tue Jan 14 19:47:41 +0000 2020   \n",
       "\n",
       "                                                 tweet_text  \n",
       "@GhanaAQ  RT @subu_caps: Nice video of @albertpresto tal...  "
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_account_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _____________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
