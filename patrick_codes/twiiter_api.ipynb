{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## This Notebook would be used to Fetch Twitter Data via Twitter API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tweepy\n",
    "from tweepy import OAuthHandler\n",
    "from tweepy import API  \n",
    "from tweepy import Cursor\n",
    "from datetime import datetime, date, time, timedelta\n",
    "from collections import Counter\n",
    "import os, sys\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Load dotenv to expose api keys to the application"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv('../.env')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API_KEY API_SECRET_KEY ACCESS_TOKEN ACCESS_TOKEN_SECRET\n"
     ]
    }
   ],
   "source": [
    "API_KEY=\"API_KEY\"\n",
    "API_SECRET_KEY=\"API_SECRET_KEY\"\n",
    "ACCESS_TOKEN=\"ACCESS_TOKEN\"\n",
    "ACCESS_TOKEN_SECRET=\"ACCESS_TOKEN_SECRET\"\n",
    "print(API_KEY, API_SECRET_KEY, ACCESS_TOKEN, ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "API_KEY = os.environ.get(API_KEY)\n",
    "API_SECRET_KEY = os.getenv(API_SECRET_KEY)\n",
    "ACCESS_TOKEN = os.getenv(ACCESS_TOKEN)\n",
    "ACCESS_TOKEN_SECRET=os.getenv(ACCESS_TOKEN_SECRET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auth = OAuthHandler(API_KEY, API_SECRET_KEY)\n",
    "auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "api = tweepy.API(auth, wait_on_rate_limit=True)\n",
    "auth_api = API(auth)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Testing Api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ozone season has ended in Kentuckiana, but air quality forecasts and the need for clean air habits continue. Learn more on the KAIRE blog. https://t.co/vC6bdhZc1z #AirQuality #helptheair #breathe https://t.co/WEWRJ3csOg\n",
      "RT @CleanAirSA: Did you know you can access ambient air quality and deposition data reports from the @AB_Enviro  Alberta Air Data Warehouse…\n"
     ]
    }
   ],
   "source": [
    "search_words = \"airquality\"\n",
    "date_since=\"2020-03-03\"  \n",
    "# Collect tweets\n",
    "tweets = tweepy.Cursor(api.search,\n",
    "              q=search_words, tweet_mode='extended',\n",
    "              lang=\"en\", \n",
    "              since=date_since\n",
    "                      ).items(2)\n",
    "# Iterate and print tweets\n",
    "for tweet in tweets:\n",
    "    print(tweet.full_text)\n",
    "   # print(tweet._json['full_text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RT @AguGeohealth: Are you a #BlackGeoscientist (anywhere in the world!) who is interested in how our environment and Earth impacts human he…\n",
      "RT @cleanaironea: 1/n\n",
      "While this is preliminary, we have tried to firstly test our open source data mining tools plus compare current trend…\n"
     ]
    }
   ],
   "source": [
    "tweets = Cursor(api.user_timeline, id='WestAfricaAQ',\n",
    "               tweet_mode='extended',\n",
    "              lang=\"en\", count=10).items(2)\n",
    "for tweet in tweets:\n",
    "    print(tweet.full_text) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> TWITTER API ALL SET UP!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hashtags= ['#airquality ','#cleanair','#airpollution' ,'#pollution',\n",
    "           '#hvac', '#airpurifier', '#indoorairquality','#health',\n",
    "           '#covid', '#air', '#climatechange',' #indoorair',\n",
    "           '#environment','#airconditioning', '#coronavirus', '#heating',\n",
    "           '#mold', '#freshair', '#safety', '#ac', '#airfilter', '#allergies',\n",
    "           '#hvacservice', '#ventilation','#wellness','#delhipollution',\n",
    "           '#airconditioner','#airqualityindex','#bhfyp',\n",
    "           'particulate matter', 'fine particulate matter','#pm2_5',\n",
    "           '#emissions', '#natureishealing','#nature','#pollutionfree',\n",
    "           '#wearethevirus']\n",
    "\n",
    "accounts = ['@GhanaAQ','@asap_eastafrica', '@WestAfricaAQ']\n",
    "\n",
    "\n",
    "geocodes = {'lagos':(\"6.48937,3.37709\"),'cape_town':(\"-33.99268,18.46654\"),\n",
    "            'joburg' : (\"-26.22081,28.03239\"),\n",
    "            'accra' : (\"5.58445,-0.20514\"),\n",
    "            'nairobi' : (\"-1.27467,36.81178\"),\n",
    "            'mombasa' : (\"-4.04549,39.66644\"),\n",
    "            'kigali' : (\"-1.95360,30.09186\"),\n",
    "            'kampala' : (\"0.32400,32.58662\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'65'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(65)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = geocodes['lagos']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.48937,3.37709,7km'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x+','+str(7)+'km'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'6.48937,3.37709'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___________________________________"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: GetOldTweets3 in /home/patrick/.local/lib/python3.6/site-packages (0.0.11)\n",
      "Requirement already satisfied: pyquery>=1.2.10 in /home/patrick/.local/lib/python3.6/site-packages (from GetOldTweets3) (1.4.1)\n",
      "Requirement already satisfied: lxml>=3.5.0 in /home/patrick/.local/lib/python3.6/site-packages (from GetOldTweets3) (4.5.0)\n",
      "Requirement already satisfied: cssselect>0.7.9 in /home/patrick/.local/lib/python3.6/site-packages (from pyquery>=1.2.10->GetOldTweets3) (1.1.0)\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install GetOldTweets3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import twint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GetOldTweets3 as got"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GetOldTweets3.manager.TweetCriteria.TweetCriteria"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "got.manager.TweetCriteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweetCriteria = got.manager.TweetCriteria().setQuerySearch('europe refugees')\\\n",
    "#                                            .setSince(\"2015-05-01\")\\\n",
    "#                                            .setUntil(\"2015-09-30\")\\\n",
    "#                                            .setMaxTweets(1)\n",
    "# tweet = got.manager.TweetManager.getTweets(tweetCriteria)[0]\n",
    "# print(tweet.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetCursor():\n",
    "    \n",
    "    import tweepy\n",
    "    from tweepy import OAuthHandler\n",
    "    from tweepy import API  \n",
    "    from tweepy import Cursor\n",
    "    from dotenv import load_dotenv\n",
    "    import os, sys\n",
    "\n",
    "    \n",
    "    def __init__(self,env_file=None):\n",
    "        if env_file is None:\n",
    "            self.env = load_dotenv('../.env')\n",
    "        else:\n",
    "            self.env = load_dotenv(env_file)\n",
    "            \n",
    "    \n",
    "    def __repr__(self):\n",
    "        \n",
    "        return \"Twitter API Auth Object\"\n",
    "            \n",
    "    \n",
    "    def get_auth(self):\n",
    "        \n",
    "        API_KEY=\"API_KEY\"\n",
    "        API_SECRET_KEY=\"API_SECRET_KEY\"\n",
    "        ACCESS_TOKEN=\"ACCESS_TOKEN\"\n",
    "        ACCESS_TOKEN_SECRET=\"ACCESS_TOKEN_SECRET\"\n",
    "        \n",
    "        self.__API_KEY = os.environ.get(API_KEY)\n",
    "        self.__API_SECRET_KEY = os.getenv(API_SECRET_KEY)\n",
    "        self.__ACCESS_TOKEN = os.getenv(ACCESS_TOKEN)\n",
    "        self.__ACCESS_TOKEN_SECRET=os.getenv(ACCESS_TOKEN_SECRET)\n",
    "        \n",
    "        try:\n",
    "            self.__auth = OAuthHandler(API_KEY, API_SECRET_KEY)\n",
    "            self.__auth.set_access_token(ACCESS_TOKEN, ACCESS_TOKEN_SECRET)\n",
    "            self.api = API(auth, wait_on_rate_limit=True)\n",
    "            self.auth_api = API(auth, retry_count=5,retry_delay=5,\n",
    "                               timeout=60, \n",
    "                                wait_on_rate_limit=True,wait_on_rate_limit_notify=True)\n",
    "            \n",
    "        except tweepy.TweepError as e:\n",
    "            print(e.reason())\n",
    "                    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetTweets(GetCursor):\n",
    "    \n",
    "    # import dependencies\n",
    "    \n",
    "    import tweepy\n",
    "    from tweepy import Cursor\n",
    "    from datetime import datetime, date, time, timedelta\n",
    "\n",
    "    \n",
    "    def __init__(self,env_file=None):\n",
    "        super().__init__(env_file)\n",
    "        self.get_auth()\n",
    "        print('Authentication successful')\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"Get tweets from Hashtags -> # & Users -> @\"\n",
    "    \n",
    "    \"\"\"\n",
    "    helper functions  \n",
    "    \n",
    "    1. limit_handled - handle wait_limit error\n",
    "    2. check_is_bot - check if handle is a bot\n",
    "    3. save_result - save data to a file\n",
    "    \n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    def limit_handled(cursor):\n",
    "        while True:\n",
    "            try:\n",
    "                yield cursor.next()\n",
    "            except tweepy.RateLimitError:\n",
    "                time.sleep(15 * 60) #default 15mins\n",
    "                \n",
    "    \n",
    "    def check_is_bot(self, handle)-> bool:\n",
    "        \n",
    "        self.is_bot = False\n",
    "        account_age_days = 0\n",
    "        \n",
    "        item = self.auth_api.get_user(handle)\n",
    "        account_created_date = item.created_at\n",
    "        delta = datetime.utcnow() - account_created_date\n",
    "        account_age_days = delta.days\n",
    "        if account_age_days < 180: #(6 months)\n",
    "            is_bot=True\n",
    "            \n",
    "        return self.is_bot\n",
    "        \n",
    "    def save_result(self, data:pd.DataFrame, path:str='../saved_data/',\n",
    "                    fname='new_file'):\n",
    "        \n",
    "        data.to_csv(path+name, index=False)\n",
    "            \n",
    "    \n",
    "    \n",
    "    def get_handle_tweets(self, handles:list=[], items_count=20):\n",
    "        self.handles = handles\n",
    "        \n",
    "        if len(self.handles) > 0: \n",
    "            for handle in self.handles:\n",
    "                print(f\"collecting tweets of -> {handle}\")\n",
    "                users_tweets = {}\n",
    "                # this helps avoid Tweepy errors like suspended users or user not found errors\n",
    "                try: \n",
    "                    item = self.auth_api.get_user(handle)\n",
    "                except tweepy.TweepError as e:\n",
    "                    print(\"found errors!!!\")\n",
    "                    continue\n",
    "                    \n",
    "                #check if handle is a potential bot    \n",
    "                if self.check_is_bot(handle):\n",
    "                    print('bot alert!!!, skipping the bad guy :(')\n",
    "                    continue\n",
    "                else:\n",
    "                    current_handle_tweets = Cursor(api.user_timeline, id=handle,\n",
    "                                                        tweet_mode='extended',\n",
    "                                                        lang=\"en\").items(items_count)\n",
    "                    \n",
    "                for tweet in current_handle_tweets:\n",
    "                    users_tweets[handle] = ({'tweet_text':tweet.full_text.encode('utf-8'),\n",
    "                                             'tweet_date':tweet._json['created_at'],\n",
    "                                            'retweet_count':tweet._json['retweet_count'],\n",
    "                                            'favorite_count':tweet._json['favorite_count']})\n",
    "        \n",
    "        self.handles_data = pd.DataFrame(users_tweets).T\n",
    "            \n",
    "        return self.handles_data\n",
    "               \n",
    "    \n",
    "    def get_tag_tweets(self, tags:list=[], geocode:str=None,\n",
    "                       radius:int=None,\n",
    "                       until_date:str=\"2020-03-30\", no_of_items=10):\n",
    "        \n",
    "        \"\"\"\n",
    "        until_date should be formatted as  YYYY-MM-DD\n",
    "        \n",
    "        geocode should be used \n",
    "        \"\"\"\n",
    "        #if geocode is not None\n",
    "        self.tags = tags \n",
    "        tags_tweets = {}\n",
    "        for tag in self.tags:\n",
    "            print(f\"collecting tweets of -> {tag}\")\n",
    "            if radius is not None and geocode is not None:\n",
    "                geocode = geocode+','+str(radius)+'km'\n",
    "            current_tag_tweets = tweepy.Cursor(api.search,\n",
    "                                               q=tag, tweet_mode='extended',\n",
    "                                               lang=\"en\", \n",
    "                                               since=until_date,\n",
    "                                               geocode=geocode,\n",
    "                                              ).items(no_of_items)\n",
    "            \n",
    "            \n",
    "            for tweet in current_tag_tweets:\n",
    "                tags_tweets[tag] = ({'tweet_text':tweet.full_text.encode('utf-8'),\n",
    "                                     'tweet_date':tweet._json['created_at'],\n",
    "                                    'retweet_count':tweet._json['retweet_count'],\n",
    "                                    'favorite_count':tweet._json['favorite_count']})\n",
    "            \n",
    "        self.tags_data = pd.DataFrame(tags_tweets).T\n",
    "        \n",
    "        return self.tags_data\n",
    "\n",
    "    \n",
    "def main():\n",
    "    return \"wip\"\n",
    "    \n",
    "if __name__== main():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authentication successful\n"
     ]
    }
   ],
   "source": [
    "get_tweet= GetTweets()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_tags = ['#airquality']#,'#cleanair','#airpollution' ,'#pollution',\n",
    "           #'#hvac', '#airpurifier']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "trial_accounts = ['@GhanaAQ']#,'@asap_eastafrica', '@WestAfricaAQ']created_at"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> test for tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting tweets of -> #airquality\n"
     ]
    }
   ],
   "source": [
    "trial_tags_result  = get_tweet.get_tag_tweets(trial_tags) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>#airquality</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Fri Oct 02 12:57:23 +0000 2020</td>\n",
       "      <td>b'.\\nHedges around #parks\\nreduce pollution le...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            favorite_count retweet_count                      tweet_date  \\\n",
       "#airquality              1             0  Fri Oct 02 12:57:23 +0000 2020   \n",
       "\n",
       "                                                    tweet_text  \n",
       "#airquality  b'.\\nHedges around #parks\\nreduce pollution le...  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_tags_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">> test for accounts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "collecting tweets of -> @GhanaAQ\n"
     ]
    }
   ],
   "source": [
    "trial_account_results = get_tweet.get_handle_tweets(trial_accounts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>favorite_count</th>\n",
       "      <th>retweet_count</th>\n",
       "      <th>tweet_date</th>\n",
       "      <th>tweet_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>@GhanaAQ</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Tue Jan 14 19:47:41 +0000 2020</td>\n",
       "      <td>b'RT @subu_caps: Nice video of @albertpresto t...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         favorite_count retweet_count                      tweet_date  \\\n",
       "@GhanaAQ              0             3  Tue Jan 14 19:47:41 +0000 2020   \n",
       "\n",
       "                                                 tweet_text  \n",
       "@GhanaAQ  b'RT @subu_caps: Nice video of @albertpresto t...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_account_results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " _____________________________________________________________________________________________________"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with BlueBird"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting bluebird\n",
      "  Downloading bluebird-0.0.4a0-py3-none-any.whl (19 kB)\n",
      "Requirement already satisfied: lxml in /home/patrick/.local/lib/python3.6/site-packages (from bluebird) (4.5.0)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from bluebird) (2.24.0)\n",
      "Collecting orderedset\n",
      "  Downloading orderedset-2.0.3.tar.gz (101 kB)\n",
      "\u001b[K     |████████████████████████████████| 101 kB 306 kB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/lib/python3/dist-packages (from requests->bluebird) (2018.1.18)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/lib/python3/dist-packages (from requests->bluebird) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /home/patrick/.local/lib/python3.6/site-packages (from requests->bluebird) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/lib/python3/dist-packages (from requests->bluebird) (2.6)\n",
      "Building wheels for collected packages: orderedset\n",
      "  Building wheel for orderedset (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for orderedset: filename=orderedset-2.0.3-cp36-cp36m-linux_x86_64.whl size=255683 sha256=bd7ff7ebd8f0f3274190dc56a7abf1b9319df19040e21cc1433ca5b5f8670266\n",
      "  Stored in directory: /home/patrick/.cache/pip/wheels/ff/f8/cf/5baf5e74a6f3a9b5cb405408673ed11dc1276599cc0877dae7\n",
      "Successfully built orderedset\n",
      "Installing collected packages: orderedset, bluebird\n",
      "Successfully installed bluebird-0.0.4a0 orderedset-2.0.3\n",
      "\u001b[33mWARNING: You are using pip version 20.2.2; however, version 20.2.3 is available.\n",
      "You should consider upgrading via the '/usr/bin/python3 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install bluebird"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
