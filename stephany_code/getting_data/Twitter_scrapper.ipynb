{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Twitter_scrapper.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyEaXoZ8_Lm-",
        "outputId": "68789b79-882b-42a8-ddcc-309e580ed99e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 176
        }
      },
      "source": [
        "from requests import get\n",
        "from requests.exceptions import RequestException\n",
        "from contextlib import closing\n",
        "from bs4 import BeautifulSoup\n",
        "import pandas as pd\n",
        "import os, sys\n",
        "\n",
        "#import fire\n",
        "\n",
        "import sys\n",
        "import os\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import re\n",
        "import string\n",
        "\n",
        "import matplotlib.dates as mdates\n",
        "import seaborn as sns\n",
        "\n",
        "# to view all columns\n",
        "pd.set_option(\"display.max.columns\", None)\n",
        "\n",
        "import tweepy\n",
        "from tweepy.streaming import StreamListener\n",
        "from tweepy import OAuthHandler\n",
        "from tweepy import Stream\n",
        "from tweepy import API\n",
        "from tweepy import Cursor\n",
        "from datetime import datetime, date, time, timedelta\n",
        "from collections import Counter\n",
        "import sys\n",
        "\n",
        "!pip install preprocessor\n",
        "import preprocessor as p"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting preprocessor\n",
            "  Downloading https://files.pythonhosted.org/packages/96/ad/d9f4ffb9bb97d1cb5bcb876b7932571d4dbaa3eff1701ad45d367f0ea27b/preprocessor-1.1.3.tar.gz\n",
            "Building wheels for collected packages: preprocessor\n",
            "  Building wheel for preprocessor (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for preprocessor: filename=preprocessor-1.1.3-cp36-none-any.whl size=4477 sha256=ebe7fa0282f5c1c5e1df27640c04150a4d4dc78df0d1c4c8b636070dbc81d2c7\n",
            "  Stored in directory: /root/.cache/pip/wheels/98/c1/a2/21fbcfd80d76576bbf148991a66f00730f541f265c7600000f\n",
            "Successfully built preprocessor\n",
            "Installing collected packages: preprocessor\n",
            "Successfully installed preprocessor-1.1.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmJkAjon_TzO"
      },
      "source": [
        "import twitter_credentials\n",
        "\n",
        "\n",
        "\n",
        "consumer_key = twitter_credentials.CONSUMER_KEY\n",
        "consumer_secret = twitter_credentials.CONSUMER_SECRET\n",
        "access_token = twitter_credentials.ACCES_TOKEN\n",
        "access_token_secret = twitter_credentials.ACCES_TOKEN_SECRET\n",
        "\n",
        "auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "auth.set_access_token(access_token, access_token_secret)\n",
        "auth_api = API(auth, wait_on_rate_limit=True)\n",
        "\n",
        "#places = auth_api.geo_search(query=\"KENYA\", granularity=\"country\")\n",
        "#place_id = places[0].id\n",
        "#places"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FOoft6I2AF1g"
      },
      "source": [
        "class tweetsearch():\n",
        "    '''\n",
        "    This is a basic class to search and download twitter data.\n",
        "    You can build up on it to extend the functionalities for more \n",
        "    sophisticated analysis\n",
        "    '''\n",
        "    def __init__(self, auth=None):\n",
        "            \n",
        "        if auth is None:\n",
        "            \n",
        "            #Variables that contains the user credentials to access Twitter API \n",
        "            #consumer_key = os.environ.get('TWITTER_API_KEY')\n",
        "            #consumer_secret = os.environ.get('TWITTER_API_SECRET')\n",
        "            #access_token = os.environ.get('TWITTER_ACCESS_TOKEN')\n",
        "            #access_token_secret = os.environ.get('TWITTER_ACCESS_TOKEN_SECRET')\n",
        "            \n",
        "\n",
        "\n",
        "            #This handles Twitter authetification and the connection to Twitter Streaming API\n",
        "            #auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "            #auth.set_access_token(access_token, access_token_secret)\n",
        "            auth=OAuthHandler(twitter_credentials.CONSUMER_KEY,twitter_credentials.CONSUMER_SECRET)\n",
        "            auth.set_access_token(twitter_credentials.ACCES_TOKEN,twitter_credentials.ACCES_TOKEN_SECRET)\n",
        "            \n",
        "\n",
        "       \n",
        "            \n",
        "\n",
        "        #            \n",
        "        self.auth = auth\n",
        "        self.api = tweepy.API(self.auth,wait_on_rate_limit=True) \n",
        "\n",
        "    def get_tweets(self,hashtag,csvfile=None):\n",
        "        \n",
        "        tweets = tweepy.Cursor(auth_api.search,q=hashtag, since_id = '2020-05-01').items(200)\n",
        "                                                                                              \n",
        "        # geocode=\"-1.286389, 36.817223,40km\",\n",
        "\n",
        "        users = []\n",
        "        followers = []\n",
        "        friends = []\n",
        "        description = []\n",
        "        Tweets = []\n",
        "        for status in tweets:\n",
        "            name = status.user.screen_name\n",
        "            desc = status.user.description\n",
        "            Tweet = status.text\n",
        "            following = status.user.friends_count\n",
        "            follower = status.user.followers_count\n",
        "            users.append(name)\n",
        "            followers.append(follower)\n",
        "            friends.append(following)\n",
        "            description.append(desc)\n",
        "            Tweets.append(Tweet) \n",
        "\n",
        "            \n",
        "        data = {'screen_name':users, 'followers':followers, 'friends':friends, 'description':description, 'tweets':Tweets}\n",
        "        tweets_df = pd.DataFrame(data)\n",
        "            \n",
        "        #     df['screen_name'] = users\n",
        "        #     df['location'] = location\n",
        "\n",
        "        if not csvfile is None:\n",
        "          #save it to file\n",
        "          tweets_df.to_csv(csvfile)\n",
        "    \n",
        "        return tweets_df"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bLNPOQ_OPVt6",
        "outputId": "5bca28e2-e102-4d9a-d186-9db407904ec2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 778
        }
      },
      "source": [
        "hashtags=[\"#airquality\",\"#cleanair\",\"#airpollution\",\"#pollution\",\"#hvac\",\"#airpurifier\" ,\"#indoorairquality\",\"#air\",\"#climatechange\",\"#indoorair\",\"#environment\" ,\"#airconditioning\",\"#heating\" , \"#freshair\", \"#airfilter\",\"#ventilation\",\"#airconditioner\",\"#airqualityindex\", \"#pm2_5 \",\"#emissions\",\"#natureishealing\",\"#nature\",\"#pollutionfree\" ,\"#wearethevirus\"]\n",
        "geocodes=[\"33.918861, 18.423300,40km\",\" -26.205681, 28.046822,40km\",\"5.550000, -0.020000,40km\",\"-1.286389, 36.817223,40km\",\"-4.043740, 39.658871,40km\",\"6.465422, 3.406448,40km\",\"-1.935114, 30.082111,40km\",\" 0.347596, 32.582520,40km\"]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ts = tweetsearch()\n",
        "for hashtag in hashtags:\n",
        "  for geocode in geocodes:\n",
        "    df = ts.get_tweets(hashtag,geocode,csvfile) \n",
        "    print(hashtag)\n",
        "    print(geocode)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "#airquality\n",
            "#airquality\n",
            "#airquality\n",
            "#airquality\n",
            "#airquality\n",
            "#airquality\n",
            "#airquality\n",
            "#airquality\n",
            "#cleanair\n",
            "#cleanair\n",
            "#cleanair\n",
            "#cleanair\n",
            "#cleanair\n",
            "#cleanair\n",
            "#cleanair\n",
            "#cleanair\n",
            "#airpollution\n",
            "#airpollution\n",
            "#airpollution\n",
            "#airpollution\n",
            "#airpollution\n",
            "#airpollution\n",
            "#airpollution\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-32-53c84da40913>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mhashtag\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mhashtags\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mgeocode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgeocodes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_tweets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtag\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mgeocode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhashtag\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-29-465b28ebf669>\u001b[0m in \u001b[0;36mget_tweets\u001b[0;34m(self, hashtag, csvfile)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mdescription\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0mTweets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mstatus\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtweets\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m             \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscreen_name\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdesc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdescription\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    195\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m             \u001b[0;31m# Reached end of current page, get the next page...\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_page\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_iterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/cursor.py\u001b[0m in \u001b[0;36mnext\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    106\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mRawParser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmethod\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__self__'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    248\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \u001b[0;31m# Set pagination mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tweepy/binder.py\u001b[0m in \u001b[0;36mexecute\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    162\u001b[0m                                     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait_on_rate_limit_notify\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m                                         \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Rate limit reached. Sleeping for: %d\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0msleep_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 164\u001b[0;31m                                     \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msleep_time\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# sleep for few extra sec\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;31m# if self.wait_on_rate_limit and self._reset_time is not None and \\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U423dOdiPktE",
        "outputId": "4f4fc36d-35de-4155-e4b4-a27a63db213c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        }
      },
      "source": [
        "df.head(10)"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>screen_name</th>\n",
              "      <th>followers</th>\n",
              "      <th>friends</th>\n",
              "      <th>description</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>kilnerevonnet</td>\n",
              "      <td>319</td>\n",
              "      <td>2745</td>\n",
              "      <td>‚ÄúNo hay que dar tantas pistas al espectador‚Äù. ...</td>\n",
              "      <td>RT @jksmith34: @jesse_kroll @linseymarr @dylan...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>RosieDuffield1</td>\n",
              "      <td>30087</td>\n",
              "      <td>6972</td>\n",
              "      <td>Labour MP Canterbury, Whitstable, the villages...</td>\n",
              "      <td>Great witnesses on our two panels today for @C...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ArunYadav0007</td>\n",
              "      <td>1398</td>\n",
              "      <td>1917</td>\n",
              "      <td>Social Activist and\\nEnvironmentalist \\n\\n#Nat...</td>\n",
              "      <td>RT @Shahnawaz_Alam1: Air pollution: ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä-NCR...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Yolande24919908</td>\n",
              "      <td>8</td>\n",
              "      <td>18</td>\n",
              "      <td>Experienced Marketing Manager with a demonstra...</td>\n",
              "      <td>Masks that are self-cleaning, #antibacterial a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>uniindianews</td>\n",
              "      <td>1990</td>\n",
              "      <td>1</td>\n",
              "      <td>Official twitter handle of UNI-India's premier...</td>\n",
              "      <td>Ministerial meeting on NCR pollution on Thursd...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Kbmohanty5</td>\n",
              "      <td>433</td>\n",
              "      <td>587</td>\n",
              "      <td>at post rairangpur.dist-mayurbhanj,odisha\\nmat...</td>\n",
              "      <td>RT @pibvijayawada: This year's Environment Min...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>3DSMjH</td>\n",
              "      <td>248</td>\n",
              "      <td>282</td>\n",
              "      <td>The platform is the channel / think #3DEXPERIE...</td>\n",
              "      <td>RT @Margeparis: Masks that are self-cleaning, ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>ManishKhurana</td>\n",
              "      <td>1151</td>\n",
              "      <td>324</td>\n",
              "      <td>Market Research | #CleanDelhi | #SwachhBharat ...</td>\n",
              "      <td>Let's segregate our waste with @WeMeanToClean ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>varun_lolz</td>\n",
              "      <td>1</td>\n",
              "      <td>49</td>\n",
              "      <td></td>\n",
              "      <td>RT @PIBHindi: ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡•á ‡§™‡§ø‡§õ‡§≤‡•á ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§Æ‡•á‡§Ç...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>DrGrays_Elgin</td>\n",
              "      <td>1026</td>\n",
              "      <td>339</td>\n",
              "      <td>Dr Gray's Hospital, Elgin. NHS Grampian. Medic...</td>\n",
              "      <td>RT @EPScotland: 9 days until #CleanAirDayüè¥! By...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       screen_name  followers  friends  \\\n",
              "0    kilnerevonnet        319     2745   \n",
              "1   RosieDuffield1      30087     6972   \n",
              "2    ArunYadav0007       1398     1917   \n",
              "3  Yolande24919908          8       18   \n",
              "4     uniindianews       1990        1   \n",
              "5       Kbmohanty5        433      587   \n",
              "6           3DSMjH        248      282   \n",
              "7    ManishKhurana       1151      324   \n",
              "8       varun_lolz          1       49   \n",
              "9    DrGrays_Elgin       1026      339   \n",
              "\n",
              "                                         description  \\\n",
              "0  ‚ÄúNo hay que dar tantas pistas al espectador‚Äù. ...   \n",
              "1  Labour MP Canterbury, Whitstable, the villages...   \n",
              "2  Social Activist and\\nEnvironmentalist \\n\\n#Nat...   \n",
              "3  Experienced Marketing Manager with a demonstra...   \n",
              "4  Official twitter handle of UNI-India's premier...   \n",
              "5  at post rairangpur.dist-mayurbhanj,odisha\\nmat...   \n",
              "6  The platform is the channel / think #3DEXPERIE...   \n",
              "7  Market Research | #CleanDelhi | #SwachhBharat ...   \n",
              "8                                                      \n",
              "9  Dr Gray's Hospital, Elgin. NHS Grampian. Medic...   \n",
              "\n",
              "                                              tweets  \n",
              "0  RT @jksmith34: @jesse_kroll @linseymarr @dylan...  \n",
              "1  Great witnesses on our two panels today for @C...  \n",
              "2  RT @Shahnawaz_Alam1: Air pollution: ‡§¶‡§ø‡§≤‡•ç‡§≤‡•Ä-NCR...  \n",
              "3  Masks that are self-cleaning, #antibacterial a...  \n",
              "4  Ministerial meeting on NCR pollution on Thursd...  \n",
              "5  RT @pibvijayawada: This year's Environment Min...  \n",
              "6  RT @Margeparis: Masks that are self-cleaning, ...  \n",
              "7  Let's segregate our waste with @WeMeanToClean ...  \n",
              "8  RT @PIBHindi: ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§∏‡§∞‡§ï‡§æ‡§∞ ‡§®‡•á ‡§™‡§ø‡§õ‡§≤‡•á ‡§µ‡§∞‡•ç‡§∑‡•ã‡§Ç ‡§Æ‡•á‡§Ç...  \n",
              "9  RT @EPScotland: 9 days until #CleanAirDayüè¥! By...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NnKwZLUtAyWK",
        "outputId": "95669ea2-37d4-47a1-c8d7-df2f888f8d04",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "hashtags=['']\n",
        "\n",
        "\n",
        "\n",
        "for geocode in geocodes:\n",
        "  tweets = tweepy.Cursor(auth_api.search,q='airquality', since_id = '2020-05-01').items(200)\n",
        "                                                                                      \n",
        "        # geocode=\"-1.286389, 36.817223,40km\",\n",
        "\n",
        "  users = []\n",
        "  followers = []\n",
        "  friends = []\n",
        "  description = []\n",
        "  Tweets = []\n",
        "\n",
        "  for status in tweets:\n",
        "      name = status.user.screen_name\n",
        "      desc = status.user.description\n",
        "      Tweet = status.text\n",
        "      following = status.user.friends_count\n",
        "      follower = status.user.followers_count\n",
        "      users.append(name)\n",
        "      followers.append(follower)\n",
        "      friends.append(following)\n",
        "      description.append(desc)\n",
        "      Tweets.append(Tweet) \n",
        "\n",
        "            \n",
        "data = {'screen_name':users, 'followers':followers, 'friends':friends, 'description':description, 'tweets':Tweets}\n",
        "tweets_df = pd.DataFrame(data)\n",
        "            \n",
        "        #     df['screen_name'] = users\n",
        "        #     df['location'] = location\n",
        "            \n",
        "tweets_df.to_csv('starting users.csv')\n",
        "tweets_df.head()\n",
        "\n",
        "\n",
        " \n",
        " \n",
        " \n",
        "\n",
        "\n"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>screen_name</th>\n",
              "      <th>followers</th>\n",
              "      <th>friends</th>\n",
              "      <th>description</th>\n",
              "      <th>tweets</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>AHAM_Voice</td>\n",
              "      <td>1641</td>\n",
              "      <td>1530</td>\n",
              "      <td>The Association of Home Appliance Manufacturer...</td>\n",
              "      <td>Want to improve your indoor #AirQuality? Get a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>forzagaribaldi</td>\n",
              "      <td>1079</td>\n",
              "      <td>1814</td>\n",
              "      <td>I like Neopan and the smell of fixer in the mo...</td>\n",
              "      <td>RT @CleanAirUK: Really excellent item on BBC R...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>MorganAshHouTx</td>\n",
              "      <td>80</td>\n",
              "      <td>980</td>\n",
              "      <td>Public Health Communication Professional - For...</td>\n",
              "      <td>@HoustonHealth joins other city and county par...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>SVNIR</td>\n",
              "      <td>394</td>\n",
              "      <td>93</td>\n",
              "      <td></td>\n",
              "      <td>ARTICLE: The Importance of Indoor Air Quality ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>WeAre4CleanAir</td>\n",
              "      <td>672</td>\n",
              "      <td>412</td>\n",
              "      <td>The national association of 155 state &amp; local ...</td>\n",
              "      <td>RT @LouAPCD: Air Quality is forecast to be Goo...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "      screen_name  followers  friends  \\\n",
              "0      AHAM_Voice       1641     1530   \n",
              "1  forzagaribaldi       1079     1814   \n",
              "2  MorganAshHouTx         80      980   \n",
              "3           SVNIR        394       93   \n",
              "4  WeAre4CleanAir        672      412   \n",
              "\n",
              "                                         description  \\\n",
              "0  The Association of Home Appliance Manufacturer...   \n",
              "1  I like Neopan and the smell of fixer in the mo...   \n",
              "2  Public Health Communication Professional - For...   \n",
              "3                                                      \n",
              "4  The national association of 155 state & local ...   \n",
              "\n",
              "                                              tweets  \n",
              "0  Want to improve your indoor #AirQuality? Get a...  \n",
              "1  RT @CleanAirUK: Really excellent item on BBC R...  \n",
              "2  @HoustonHealth joins other city and county par...  \n",
              "3  ARTICLE: The Importance of Indoor Air Quality ...  \n",
              "4  RT @LouAPCD: Air Quality is forecast to be Goo...  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Ph9_zpqH9VD"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}